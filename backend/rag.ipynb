{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9802e8ba",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfa8e5b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from helix.client import Query, Client\n",
    "from helix.instance import Instance\n",
    "from helix.types import Payload\n",
    "from collections import defaultdict\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2b748e",
   "metadata": {},
   "source": [
    "## Create docs folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbb1f737",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCS_DIR = Path(\"../docs\")\n",
    "OUTPUT_DIR = Path(\"./processed_docs\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2a604ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'INHERIT': './docs/_global/mkdocs.yml',\n",
       " 'site_name': 'After Effects Scripting Guide',\n",
       " 'site_url': 'https://ae-scripting.docsforadobe.dev/',\n",
       " 'repo_url': 'https://github.com/docsforadobe/after-effects-scripting-guide/',\n",
       " 'repo_name': 'after-effects-scripting-guide',\n",
       " 'nav': [{'Home': 'index.md'},\n",
       "  {'Introduction': [{'Overview': 'introduction/overview.md'},\n",
       "    {'Javascript for After Effects': 'introduction/javascript.md'},\n",
       "    {'After Effects Scripting Changlog': 'introduction/changelog.md'},\n",
       "    {'After Effects Object Model': 'introduction/objectmodel.md'},\n",
       "    {'After Effects Class Hierarchy': 'introduction/classhierarchy.md'}]},\n",
       "  {'General': [{'Globals': 'general/globals.md'},\n",
       "    {'Application': 'general/application.md'},\n",
       "    {'Project': 'general/project.md'},\n",
       "    {'System': 'general/system.md'}]},\n",
       "  {'Item': [{'Item object': 'item/item.md'},\n",
       "    {'ItemCollection': 'item/itemcollection.md'},\n",
       "    {'AVItem': 'item/avitem.md'},\n",
       "    {'CompItem': 'item/compitem.md'},\n",
       "    {'FolderItem': 'item/folderitem.md'},\n",
       "    {'FootageItem': 'item/footageitem.md'}]},\n",
       "  {'Layer': [{'Layer object': 'layer/layer.md'},\n",
       "    {'LayerCollection': 'layer/layercollection.md'},\n",
       "    {'AVLayer': 'layer/avlayer.md'},\n",
       "    {'CameraLayer': 'layer/cameralayer.md'},\n",
       "    {'LightLayer': 'layer/lightlayer.md'},\n",
       "    {'ShapeLayer': 'layer/shapelayer.md'},\n",
       "    {'TextLayer': 'layer/textlayer.md'},\n",
       "    {'ThreeDModelLayer': 'layer/threedmodellayer.md'}]},\n",
       "  {'Property': [{'Property object': 'property/property.md'},\n",
       "    {'PropertyBase': 'property/propertybase.md'},\n",
       "    {'PropertyGroup': 'property/propertygroup.md'},\n",
       "    {'MaskPropertyGroup': 'property/maskpropertygroup.md'}]},\n",
       "  {'Render Queue': [{'RenderQueue object': 'renderqueue/renderqueue.md'},\n",
       "    {'RQItemCollection': 'renderqueue/rqitemcollection.md'},\n",
       "    {'RenderQueueItem': 'renderqueue/renderqueueitem.md'},\n",
       "    {'OMCollection': 'renderqueue/omcollection.md'},\n",
       "    {'OutputModule': 'renderqueue/outputmodule.md'}]},\n",
       "  {'Sources': [{'FileSource': 'sources/filesource.md'},\n",
       "    {'FootageSource': 'sources/footagesource.md'},\n",
       "    {'PlaceholderSource': 'sources/placeholdersource.md'},\n",
       "    {'SolidSource': 'sources/solidsource.md'}]},\n",
       "  {'Text': [{'CharacterRange': 'text/characterrange.md'},\n",
       "    {'ComposedLineRange': 'text/composedlinerange.md'},\n",
       "    {'FontObject': 'text/fontobject.md'},\n",
       "    {'FontsObject': 'text/fontsobject.md'},\n",
       "    {'ParagraphRange': 'text/paragraphrange.md'},\n",
       "    {'TextDocument': 'text/textdocument.md'}]},\n",
       "  {'Other': [{'Collection': 'other/collection.md'},\n",
       "    {'ImportOptions': 'other/importoptions.md'},\n",
       "    {'KeyframeEase': 'other/keyframeease.md'},\n",
       "    {'MarkerValue': 'other/markervalue.md'},\n",
       "    {'Preferences': 'other/preferences.md'},\n",
       "    {'Settings': 'other/settings.md'},\n",
       "    {'Shape': 'other/shape.md'},\n",
       "    {'View': 'other/view.md'},\n",
       "    {'Viewer': 'other/viewer.md'},\n",
       "    {'ViewOptions': 'other/viewoptions.md'}]},\n",
       "  {'Match Names': [{'Layers': [{'AV Layer Match Names': 'matchnames/layer/avlayer.md'},\n",
       "      {'3D Layer Match Names': 'matchnames/layer/3dlayer.md'},\n",
       "      {'Camera Layer Match Names': 'matchnames/layer/cameralayer.md'},\n",
       "      {'Light Layer Match Names': 'matchnames/layer/lightlayer.md'},\n",
       "      {'Text Layer Match Names': 'matchnames/layer/textlayer.md'},\n",
       "      {'Shape Layer Match Names': 'matchnames/layer/shapelayer.md'},\n",
       "      {'Layer Styles Match Names': 'matchnames/layer/layerstyles.md'}]},\n",
       "    {'Effects': [{'First-Party Effect Match Names': 'matchnames/effects/firstparty.md'}]}]}],\n",
       " 'extra': {'overrides': {}},\n",
       " 'extra_css': ['_static/extra.css'],\n",
       " 'extra_javascript': ['_static/extra.js'],\n",
       " 'markdown_extensions': {},\n",
       " 'plugins': {}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../mkdocs.yml\", \"r\") as f:\n",
    "    mkdocs_config = yaml.safe_load(f)\n",
    "\n",
    "mkdocs_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72b93acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Home': 'index.md'},\n",
       " {'Introduction': [{'Overview': 'introduction/overview.md'},\n",
       "   {'Javascript for After Effects': 'introduction/javascript.md'},\n",
       "   {'After Effects Scripting Changlog': 'introduction/changelog.md'},\n",
       "   {'After Effects Object Model': 'introduction/objectmodel.md'},\n",
       "   {'After Effects Class Hierarchy': 'introduction/classhierarchy.md'}]},\n",
       " {'General': [{'Globals': 'general/globals.md'},\n",
       "   {'Application': 'general/application.md'},\n",
       "   {'Project': 'general/project.md'},\n",
       "   {'System': 'general/system.md'}]},\n",
       " {'Item': [{'Item object': 'item/item.md'},\n",
       "   {'ItemCollection': 'item/itemcollection.md'},\n",
       "   {'AVItem': 'item/avitem.md'},\n",
       "   {'CompItem': 'item/compitem.md'},\n",
       "   {'FolderItem': 'item/folderitem.md'},\n",
       "   {'FootageItem': 'item/footageitem.md'}]},\n",
       " {'Layer': [{'Layer object': 'layer/layer.md'},\n",
       "   {'LayerCollection': 'layer/layercollection.md'},\n",
       "   {'AVLayer': 'layer/avlayer.md'},\n",
       "   {'CameraLayer': 'layer/cameralayer.md'},\n",
       "   {'LightLayer': 'layer/lightlayer.md'},\n",
       "   {'ShapeLayer': 'layer/shapelayer.md'},\n",
       "   {'TextLayer': 'layer/textlayer.md'},\n",
       "   {'ThreeDModelLayer': 'layer/threedmodellayer.md'}]},\n",
       " {'Property': [{'Property object': 'property/property.md'},\n",
       "   {'PropertyBase': 'property/propertybase.md'},\n",
       "   {'PropertyGroup': 'property/propertygroup.md'},\n",
       "   {'MaskPropertyGroup': 'property/maskpropertygroup.md'}]},\n",
       " {'Render Queue': [{'RenderQueue object': 'renderqueue/renderqueue.md'},\n",
       "   {'RQItemCollection': 'renderqueue/rqitemcollection.md'},\n",
       "   {'RenderQueueItem': 'renderqueue/renderqueueitem.md'},\n",
       "   {'OMCollection': 'renderqueue/omcollection.md'},\n",
       "   {'OutputModule': 'renderqueue/outputmodule.md'}]},\n",
       " {'Sources': [{'FileSource': 'sources/filesource.md'},\n",
       "   {'FootageSource': 'sources/footagesource.md'},\n",
       "   {'PlaceholderSource': 'sources/placeholdersource.md'},\n",
       "   {'SolidSource': 'sources/solidsource.md'}]},\n",
       " {'Text': [{'CharacterRange': 'text/characterrange.md'},\n",
       "   {'ComposedLineRange': 'text/composedlinerange.md'},\n",
       "   {'FontObject': 'text/fontobject.md'},\n",
       "   {'FontsObject': 'text/fontsobject.md'},\n",
       "   {'ParagraphRange': 'text/paragraphrange.md'},\n",
       "   {'TextDocument': 'text/textdocument.md'}]},\n",
       " {'Other': [{'Collection': 'other/collection.md'},\n",
       "   {'ImportOptions': 'other/importoptions.md'},\n",
       "   {'KeyframeEase': 'other/keyframeease.md'},\n",
       "   {'MarkerValue': 'other/markervalue.md'},\n",
       "   {'Preferences': 'other/preferences.md'},\n",
       "   {'Settings': 'other/settings.md'},\n",
       "   {'Shape': 'other/shape.md'},\n",
       "   {'View': 'other/view.md'},\n",
       "   {'Viewer': 'other/viewer.md'},\n",
       "   {'ViewOptions': 'other/viewoptions.md'}]},\n",
       " {'Match Names': [{'Layers': [{'AV Layer Match Names': 'matchnames/layer/avlayer.md'},\n",
       "     {'3D Layer Match Names': 'matchnames/layer/3dlayer.md'},\n",
       "     {'Camera Layer Match Names': 'matchnames/layer/cameralayer.md'},\n",
       "     {'Light Layer Match Names': 'matchnames/layer/lightlayer.md'},\n",
       "     {'Text Layer Match Names': 'matchnames/layer/textlayer.md'},\n",
       "     {'Shape Layer Match Names': 'matchnames/layer/shapelayer.md'},\n",
       "     {'Layer Styles Match Names': 'matchnames/layer/layerstyles.md'}]},\n",
       "   {'Effects': [{'First-Party Effect Match Names': 'matchnames/effects/firstparty.md'}]}]}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nav = mkdocs_config.get(\"nav\", {})\n",
    "nav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4c8ee75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract all markdown files from the mkdocs.yml file\n",
    "def extract_md_files(nav_item, parent_section=\"\"):\n",
    "    md_files = []\n",
    "    \n",
    "    if isinstance(nav_item, dict):\n",
    "        for section, content in nav_item.items():\n",
    "            section_files = extract_md_files(content, section)\n",
    "            md_files.extend(section_files)\n",
    "    elif isinstance(nav_item, list):\n",
    "        for item in nav_item:\n",
    "            section_files = extract_md_files(item, parent_section)\n",
    "            md_files.extend(section_files)\n",
    "    elif isinstance(nav_item, str) and nav_item.endswith(\".md\"):\n",
    "    \n",
    "        md_files.append({\n",
    "            \"path\": nav_item,\n",
    "            \"section\": parent_section\n",
    "        })\n",
    "    \n",
    "    return md_files\n",
    "\n",
    "all_md_files = []\n",
    "for item in nav:\n",
    "    all_md_files.extend(extract_md_files(item))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f74a1ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'path': 'index.md', 'section': 'Home'},\n",
       " {'path': 'introduction/overview.md', 'section': 'Overview'},\n",
       " {'path': 'introduction/javascript.md',\n",
       "  'section': 'Javascript for After Effects'},\n",
       " {'path': 'introduction/changelog.md',\n",
       "  'section': 'After Effects Scripting Changlog'},\n",
       " {'path': 'introduction/objectmodel.md',\n",
       "  'section': 'After Effects Object Model'},\n",
       " {'path': 'introduction/classhierarchy.md',\n",
       "  'section': 'After Effects Class Hierarchy'},\n",
       " {'path': 'general/globals.md', 'section': 'Globals'},\n",
       " {'path': 'general/application.md', 'section': 'Application'},\n",
       " {'path': 'general/project.md', 'section': 'Project'},\n",
       " {'path': 'general/system.md', 'section': 'System'},\n",
       " {'path': 'item/item.md', 'section': 'Item object'},\n",
       " {'path': 'item/itemcollection.md', 'section': 'ItemCollection'},\n",
       " {'path': 'item/avitem.md', 'section': 'AVItem'},\n",
       " {'path': 'item/compitem.md', 'section': 'CompItem'},\n",
       " {'path': 'item/folderitem.md', 'section': 'FolderItem'},\n",
       " {'path': 'item/footageitem.md', 'section': 'FootageItem'},\n",
       " {'path': 'layer/layer.md', 'section': 'Layer object'},\n",
       " {'path': 'layer/layercollection.md', 'section': 'LayerCollection'},\n",
       " {'path': 'layer/avlayer.md', 'section': 'AVLayer'},\n",
       " {'path': 'layer/cameralayer.md', 'section': 'CameraLayer'},\n",
       " {'path': 'layer/lightlayer.md', 'section': 'LightLayer'},\n",
       " {'path': 'layer/shapelayer.md', 'section': 'ShapeLayer'},\n",
       " {'path': 'layer/textlayer.md', 'section': 'TextLayer'},\n",
       " {'path': 'layer/threedmodellayer.md', 'section': 'ThreeDModelLayer'},\n",
       " {'path': 'property/property.md', 'section': 'Property object'},\n",
       " {'path': 'property/propertybase.md', 'section': 'PropertyBase'},\n",
       " {'path': 'property/propertygroup.md', 'section': 'PropertyGroup'},\n",
       " {'path': 'property/maskpropertygroup.md', 'section': 'MaskPropertyGroup'},\n",
       " {'path': 'renderqueue/renderqueue.md', 'section': 'RenderQueue object'},\n",
       " {'path': 'renderqueue/rqitemcollection.md', 'section': 'RQItemCollection'},\n",
       " {'path': 'renderqueue/renderqueueitem.md', 'section': 'RenderQueueItem'},\n",
       " {'path': 'renderqueue/omcollection.md', 'section': 'OMCollection'},\n",
       " {'path': 'renderqueue/outputmodule.md', 'section': 'OutputModule'},\n",
       " {'path': 'sources/filesource.md', 'section': 'FileSource'},\n",
       " {'path': 'sources/footagesource.md', 'section': 'FootageSource'},\n",
       " {'path': 'sources/placeholdersource.md', 'section': 'PlaceholderSource'},\n",
       " {'path': 'sources/solidsource.md', 'section': 'SolidSource'},\n",
       " {'path': 'text/characterrange.md', 'section': 'CharacterRange'},\n",
       " {'path': 'text/composedlinerange.md', 'section': 'ComposedLineRange'},\n",
       " {'path': 'text/fontobject.md', 'section': 'FontObject'},\n",
       " {'path': 'text/fontsobject.md', 'section': 'FontsObject'},\n",
       " {'path': 'text/paragraphrange.md', 'section': 'ParagraphRange'},\n",
       " {'path': 'text/textdocument.md', 'section': 'TextDocument'},\n",
       " {'path': 'other/collection.md', 'section': 'Collection'},\n",
       " {'path': 'other/importoptions.md', 'section': 'ImportOptions'},\n",
       " {'path': 'other/keyframeease.md', 'section': 'KeyframeEase'},\n",
       " {'path': 'other/markervalue.md', 'section': 'MarkerValue'},\n",
       " {'path': 'other/preferences.md', 'section': 'Preferences'},\n",
       " {'path': 'other/settings.md', 'section': 'Settings'},\n",
       " {'path': 'other/shape.md', 'section': 'Shape'},\n",
       " {'path': 'other/view.md', 'section': 'View'},\n",
       " {'path': 'other/viewer.md', 'section': 'Viewer'},\n",
       " {'path': 'other/viewoptions.md', 'section': 'ViewOptions'},\n",
       " {'path': 'matchnames/layer/avlayer.md', 'section': 'AV Layer Match Names'},\n",
       " {'path': 'matchnames/layer/3dlayer.md', 'section': '3D Layer Match Names'},\n",
       " {'path': 'matchnames/layer/cameralayer.md',\n",
       "  'section': 'Camera Layer Match Names'},\n",
       " {'path': 'matchnames/layer/lightlayer.md',\n",
       "  'section': 'Light Layer Match Names'},\n",
       " {'path': 'matchnames/layer/textlayer.md',\n",
       "  'section': 'Text Layer Match Names'},\n",
       " {'path': 'matchnames/layer/shapelayer.md',\n",
       "  'section': 'Shape Layer Match Names'},\n",
       " {'path': 'matchnames/layer/layerstyles.md',\n",
       "  'section': 'Layer Styles Match Names'},\n",
       " {'path': 'matchnames/effects/firstparty.md',\n",
       "  'section': 'First-Party Effect Match Names'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_md_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f421f2df",
   "metadata": {},
   "source": [
    "## Chunk MD files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b252a90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# chunk by separators\n",
    "def chunk_by_separators(content):\n",
    "\n",
    "    sections = re.split(r'\\n---\\n', content)\n",
    "    \n",
    "    chunks = []\n",
    "    for i, section in enumerate(sections):\n",
    "        section = section.strip()\n",
    "        if not section:\n",
    "            continue\n",
    "        \n",
    "        if i > 0:\n",
    "            section = \"---\\n\\n\" + section\n",
    "            \n",
    "        chunks.append(section)\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "\n",
    "# determine which chunking method to use\n",
    "def smart_api_chunking(content, file_path):\n",
    "    \n",
    "    separator_count = len(re.findall(r'\\n---\\n', content))\n",
    "    \n",
    "    if separator_count >= 3:\n",
    "        return chunk_by_separators(content)\n",
    "    else:\n",
    "        #fall back to chonkie if separator-based chunking fails\n",
    "        from chonkie import SentenceChunker\n",
    "        chunker = SentenceChunker(chunk_size=1024, chunk_overlap=0)\n",
    "        return [chunk.text for chunk in chunker.chunk(content)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "620e1865",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract embeddable content and code blocks\n",
    "def extract_embeddable_content_and_code(chunk_text):\n",
    "\n",
    "    code_blocks = []\n",
    "    \n",
    "    #extract code blocks\n",
    "    code_fence_pattern = r'```[\\s\\S]*?```'\n",
    "    code_fences = re.findall(code_fence_pattern, chunk_text)\n",
    "    code_blocks.extend(code_fences)\n",
    "    \n",
    "    #remove code blocks from chunk_text\n",
    "    embeddable_text = re.sub(code_fence_pattern, '', chunk_text)\n",
    "    \n",
    "    #remove paragraph markers\n",
    "    embeddable_text = re.sub(r'¶', '', embeddable_text) \n",
    "    embeddable_text = re.sub(r'\\n\\s*\\n', '\\n\\n', embeddable_text) \n",
    "    embeddable_text = embeddable_text.strip()\n",
    "    \n",
    "    #extract signatures\n",
    "    signature_pattern = r'`[^`\\n]+\\([^)]*\\)`'\n",
    "    signatures = re.findall(signature_pattern, embeddable_text)\n",
    "    \n",
    "    #extract title\n",
    "    title_match = re.search(r'^###?\\s*(.+)', chunk_text, re.MULTILINE)\n",
    "    title = title_match.group(1).strip() if title_match else \"Unknown\"\n",
    "    \n",
    "    #extract metadata\n",
    "    metadata = {\n",
    "        'title': title,\n",
    "        'signatures': signatures,\n",
    "        'has_code_examples': len(code_fences) > 0,\n",
    "        'has_inline_code': len(re.findall(r'`[^`\\n]+`', embeddable_text)) > 0\n",
    "    }\n",
    "    \n",
    "    return embeddable_text, code_blocks, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c665b38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping index.md file: ../docs/index.md\n",
      "Skipping introduction folder file: ../docs/introduction/overview.md\n",
      "Skipping introduction folder file: ../docs/introduction/javascript.md\n",
      "Skipping introduction folder file: ../docs/introduction/changelog.md\n",
      "Skipping introduction folder file: ../docs/introduction/objectmodel.md\n",
      "Skipping introduction folder file: ../docs/introduction/classhierarchy.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/putt/Documents/Github/docsforadobe_rag/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total processed documents: 748\n"
     ]
    }
   ],
   "source": [
    "processed_docs = []\n",
    "\n",
    "#process each markdown file\n",
    "for md_file in all_md_files:\n",
    "    file_path = DOCS_DIR / md_file[\"path\"]\n",
    "    section = md_file[\"section\"]\n",
    "    \n",
    "    #skip if file doesn't exist\n",
    "    if not file_path.exists():\n",
    "        print(f\"Warning: File {file_path} not found, skipping.\")\n",
    "        continue\n",
    "    \n",
    "    #skip index.md file\n",
    "    if file_path.name == \"index.md\":\n",
    "        print(f\"Skipping index.md file: {file_path}\")\n",
    "        continue\n",
    "\n",
    "    #skip introduction folder files\n",
    "    if \"introduction\" in file_path.parts:\n",
    "        print(f\"Skipping introduction folder file: {file_path}\")\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "\n",
    "    #chunk the content\n",
    "    chunks = smart_api_chunking(content, file_path)\n",
    "    \n",
    "    #process each chunk\n",
    "    for i, chunk_text in enumerate(chunks):\n",
    "        embeddable_text, code_blocks, metadata = extract_embeddable_content_and_code(chunk_text)\n",
    "        \n",
    "        processed_docs.append({\n",
    "            \"title\": metadata['title'],\n",
    "            \"content\": embeddable_text,  \n",
    "            \"full_content\": chunk_text,  \n",
    "            \"code_blocks\": code_blocks,  \n",
    "            \"signatures\": metadata['signatures'],\n",
    "            \"has_code_examples\": metadata['has_code_examples'],\n",
    "            \"path\": str(file_path),\n",
    "            \"section\": section,\n",
    "            \"category\": file_path.parent.name,\n",
    "            \"chunk_id\": i,\n",
    "            \"total_chunks\": len(chunks)\n",
    "        })\n",
    "\n",
    "\n",
    "print(f\"\\nTotal processed documents: {len(processed_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc50a41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary:\n",
      "  general: 116 chunks from 4 files\n",
      "  item: 86 chunks from 6 files\n",
      "  layer: 150 chunks from 10 files\n",
      "  property: 98 chunks from 4 files\n",
      "  renderqueue: 51 chunks from 5 files\n",
      "  sources: 21 chunks from 4 files\n",
      "  text: 130 chunks from 6 files\n",
      "  other: 73 chunks from 10 files\n",
      "  effects: 23 chunks from 1 files\n"
     ]
    }
   ],
   "source": [
    "#save to processed_docs.json\n",
    "with open(OUTPUT_DIR / \"processed_docs.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(processed_docs, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "#create a summary of the processed docs\n",
    "summary = {}\n",
    "for doc in processed_docs:\n",
    "    category = doc['category']\n",
    "    if category not in summary:\n",
    "        summary[category] = {\n",
    "            'count': 0,\n",
    "            'files': set()\n",
    "        }\n",
    "    summary[category]['count'] += 1\n",
    "    summary[category]['files'].add(doc['path'].split('/')[-1])\n",
    "\n",
    "#create a summary of the processed docs\n",
    "for category in summary:\n",
    "    summary[category]['files'] = list(summary[category]['files'])\n",
    "\n",
    "#save the summary to processing_summary.json\n",
    "with open(OUTPUT_DIR / \"processing_summary.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(summary, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "\n",
    "print(\"summary:\")\n",
    "for category, info in summary.items():\n",
    "    print(f\"  {category}: {info['count']} chunks from {len(info['files'])} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2414084b",
   "metadata": {},
   "source": [
    "## Generate Gemini Embeddings For Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7773d821",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE = OUTPUT_DIR / \"processed_docs.json\"\n",
    "OUTPUT_FILE = OUTPUT_DIR / \"embedded_docs.json\"\n",
    "CHECKPOINT_FILE = OUTPUT_DIR / \"embedding_checkpoint.json\"\n",
    "\n",
    "api_key = os.environ.get(\"GOOGLE_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"GOOGLE_API_KEY environment variable not set\")\n",
    "\n",
    "client = genai.Client(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7b1cdeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748 processed documents\n"
     ]
    }
   ],
   "source": [
    "with open(INPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    processed_docs = json.load(f)\n",
    "\n",
    "print(f\"{len(processed_docs)} processed documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d81276ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_docs = []\n",
    "processed_indices = set()\n",
    "if CHECKPOINT_FILE.exists():\n",
    "    try:\n",
    "        with open(CHECKPOINT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "            embedded_docs = json.load(f)\n",
    "            processed_indices = {doc.get(\"original_index\") for doc in embedded_docs if \"original_index\" in doc}\n",
    "    except json.JSONDecodeError:\n",
    "        if CHECKPOINT_FILE.exists():\n",
    "            backup_file = CHECKPOINT_FILE.with_suffix('.json.bak')\n",
    "            CHECKPOINT_FILE.rename(backup_file)\n",
    "            print(f\"usingcheckpoint {backup_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6021cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding batch size and pause because gemini rate limits\n",
    "total_docs = len(processed_docs)\n",
    "BATCH_SIZE = 145\n",
    "BATCH_PAUSE = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca65ff60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:73: SyntaxWarning: invalid escape sequence '\\g'\n",
      "<>:73: SyntaxWarning: invalid escape sequence '\\g'\n",
      "/var/folders/hw/7s12dxpd5mn_4_5rsxc93khw0000gn/T/ipykernel_21623/407562345.py:73: SyntaxWarning: invalid escape sequence '\\g'\n",
      "  print(f\"\\generated embeddings for {len(embedded_docs)}/{total_docs} documents\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "batch 1/6\n",
      "documents 0 to 144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch 1: 100%|██████████| 145/145 [00:31<00:00,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "batch complete, waiting 60 seconds before starting next batch...\n",
      "Next batch starting in 1 seconds....\n",
      "starting next batch...\n",
      "\n",
      "batch 2/6\n",
      "documents 145 to 289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch 2: 100%|██████████| 145/145 [00:30<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "batch complete, waiting 60 seconds before starting next batch...\n",
      "Next batch starting in 1 seconds....\n",
      "starting next batch...\n",
      "\n",
      "batch 3/6\n",
      "documents 290 to 434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch 3: 100%|██████████| 145/145 [00:36<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "batch complete, waiting 60 seconds before starting next batch...\n",
      "Next batch starting in 1 seconds....\n",
      "starting next batch...\n",
      "\n",
      "batch 4/6\n",
      "documents 435 to 579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch 4: 100%|██████████| 145/145 [00:32<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "batch complete, waiting 60 seconds before starting next batch...\n",
      "Next batch starting in 1 seconds....\n",
      "starting next batch...\n",
      "\n",
      "batch 5/6\n",
      "documents 580 to 724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch 5: 100%|██████████| 145/145 [00:32<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "batch complete, waiting 60 seconds before starting next batch...\n",
      "Next batch starting in 1 seconds....\n",
      "starting next batch...\n",
      "\n",
      "batch 6/6\n",
      "documents 725 to 747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch 6: 100%|██████████| 23/23 [00:06<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\generated embeddings for 748/748 documents\n",
      "saved to: processed_docs/embedded_docs.json\n"
     ]
    }
   ],
   "source": [
    "for batch_start in range(0, len(processed_docs), BATCH_SIZE):\n",
    "    batch_end = min(batch_start + BATCH_SIZE, len(processed_docs))\n",
    "    current_batch = processed_docs[batch_start:batch_end]\n",
    "    \n",
    "    print(f\"\\nbatch {batch_start//BATCH_SIZE + 1}/{(len(processed_docs) + BATCH_SIZE - 1)//BATCH_SIZE}\")\n",
    "    print(f\"documents {batch_start} to {batch_end-1}\")\n",
    "    \n",
    "    #process each document in the current batch\n",
    "    for idx, doc in enumerate(tqdm(current_batch, desc=f\"batch {batch_start//BATCH_SIZE + 1}\")):\n",
    "        success = False\n",
    "        max_retries = 3\n",
    "        retry_count = 0\n",
    "        \n",
    "        #retry if rate limit is hit\n",
    "        while not success and retry_count < max_retries:\n",
    "            try:\n",
    "                #generate the embedding\n",
    "                result = client.models.embed_content(\n",
    "                    model=\"models/text-embedding-004\",\n",
    "                    contents=doc[\"content\"],\n",
    "                    config=types.EmbedContentConfig(task_type=\"RETRIEVAL_DOCUMENT\")\n",
    "                )\n",
    "                #extract the embedding\n",
    "                embedding_list = result.embeddings[0].values\n",
    "                #add the embedding to the document\n",
    "                doc_copy = doc.copy()\n",
    "                doc_copy[\"embedding\"] = embedding_list\n",
    "                doc_copy[\"original_index\"] = batch_start + idx\n",
    "                embedded_docs.append(doc_copy)\n",
    "                success = True\n",
    "                \n",
    "                #save the checkpoint \n",
    "                if len(embedded_docs) % 10 == 0:\n",
    "                    temp_file = CHECKPOINT_FILE.with_suffix('.tmp')\n",
    "                    with open(temp_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                        json.dump(embedded_docs, f, ensure_ascii=False)\n",
    "                    temp_file.replace(CHECKPOINT_FILE)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                error_message = str(e)\n",
    "                if \"RESOURCE_EXHAUSTED\" in error_message or \"429\" in error_message:\n",
    "                    retry_count += 1\n",
    "                    sleep_time = (2 ** retry_count) + random.uniform(0, 1)\n",
    "                    print(f\"rate limit hit, retrying in {sleep_time:.1f} seconds\")\n",
    "                    time.sleep(sleep_time)\n",
    "                else:\n",
    "                    print(f\"error generating embedding for document {batch_start + idx}: {error_message}\")\n",
    "                    retry_count += 1\n",
    "                    time.sleep(1)\n",
    "        \n",
    "        if not success:\n",
    "            print(f\"failed to generate embedding for document {batch_start + idx} after {max_retries} retries\")\n",
    "        \n",
    "    \n",
    "    temp_file = CHECKPOINT_FILE.with_suffix('.tmp')\n",
    "    with open(temp_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(embedded_docs, f, ensure_ascii=False)\n",
    "    temp_file.replace(CHECKPOINT_FILE)\n",
    "    \n",
    "    if batch_end < len(processed_docs):\n",
    "        print(f\"\\nbatch complete, waiting {BATCH_PAUSE} seconds before starting next batch...\")\n",
    "        for remaining in range(BATCH_PAUSE, 0, -1):\n",
    "            print(f\"Next batch starting in {remaining} seconds...\", end=\"\\r\")\n",
    "            time.sleep(1)\n",
    "        print(\"\\nstarting next batch...\")\n",
    "\n",
    "\n",
    "temp_file = OUTPUT_FILE.with_suffix('.tmp')\n",
    "with open(temp_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(embedded_docs, f, ensure_ascii=False)\n",
    "temp_file.replace(OUTPUT_FILE)\n",
    "\n",
    "print(f\"\\generated embeddings for {len(embedded_docs)}/{total_docs} documents\")\n",
    "print(f\"saved to: {OUTPUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1841010d",
   "metadata": {},
   "source": [
    "## Setup HelixDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6213247f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[HELIX]\u001b[0m Helix instance found at 'http://0.0.0.0:6969'\n"
     ]
    }
   ],
   "source": [
    "db = Client(local=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59641516",
   "metadata": {},
   "source": [
    "## Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f29892e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class load_docs_rag(Query):\n",
    "    def __init__(self, chapters):\n",
    "        super().__init__()\n",
    "        self.chapters = chapters\n",
    "    \n",
    "    def query(self):\n",
    "        return [{\"chapters\": self.chapters}]\n",
    "    \n",
    "    def response(self, response):\n",
    "        return response\n",
    "    \n",
    "class get_chapter_content(Query):\n",
    "    def __init__(self, chapter_id):\n",
    "        super().__init__()\n",
    "        self.chapter_id = chapter_id\n",
    "    \n",
    "    def query(self):\n",
    "        return [{\"chapter_id\": self.chapter_id}]\n",
    "    \n",
    "    def response(self, response):\n",
    "        return response\n",
    "\n",
    "class search_docs_rag(Query):\n",
    "    def __init__(self, query_vector, k=5):\n",
    "        super().__init__()\n",
    "        self.query_vector = query_vector\n",
    "        self.k = k\n",
    "    \n",
    "    def query(self):\n",
    "        return [{\"query\": self.query_vector, \"k\": self.k}]\n",
    "    \n",
    "    def response(self, response):\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e35d1cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Chapter 0 (general): 4 files, 116 chunks\n",
      "  Chapter 1 (item): 6 files, 86 chunks\n",
      "  Chapter 2 (layer): 10 files, 150 chunks\n",
      "  Chapter 3 (property): 4 files, 98 chunks\n",
      "  Chapter 4 (renderqueue): 5 files, 51 chunks\n",
      "  Chapter 5 (sources): 4 files, 21 chunks\n",
      "  Chapter 6 (text): 6 files, 130 chunks\n",
      "  Chapter 7 (other): 10 files, 73 chunks\n",
      "  Chapter 8 (effects): 1 files, 23 chunks\n",
      "\n",
      "9 chapters, 748 chunks across all categories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[HELIX]\u001b[0m Querying 'http://0.0.0.0:6969/load_docs_rag': 100%|██████████| 1/1 [00:01<00:00,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ HelixDB full load result: [{'Success': 'Success'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#organize the data for helixdb\n",
    "def organize_all_data_for_helix(docs):\n",
    "    chapters_data = defaultdict(lambda: defaultdict(list))\n",
    "    \n",
    "    #organize the data by category and file name\n",
    "    for doc in docs:\n",
    "        category = doc['category']\n",
    "        file_name = doc['path'].split('/')[-1]\n",
    "        \n",
    "        #add the data to the chapters_data dictionary\n",
    "        chapters_data[category][file_name].append({\n",
    "            'chunk': doc['content'],\n",
    "            'vector': doc['embedding']\n",
    "        })\n",
    "    \n",
    "    helix_chapters = []\n",
    "\n",
    "    #get the category names\n",
    "    category_names = list(chapters_data.keys())\n",
    "    \n",
    "    #create the subchapters\n",
    "    for chapter_idx, (category, files) in enumerate(chapters_data.items()):\n",
    "        subchapters = []\n",
    "        #create the subchapters\n",
    "        for file_name, chunks in files.items():\n",
    "            #create the subchapters\n",
    "            subchapters.append({\n",
    "                'title': file_name,\n",
    "                'content': f\"After Effects {category} documentation for {file_name}\",\n",
    "                'chunks': chunks\n",
    "            })\n",
    "        \n",
    "        #add the subchapters to the helix chapters\n",
    "        helix_chapters.append({\n",
    "            'id': chapter_idx,\n",
    "            'subchapters': subchapters\n",
    "        })\n",
    "    \n",
    "    return helix_chapters, category_names\n",
    "\n",
    "all_helix_data, category_list = organize_all_data_for_helix(embedded_docs)\n",
    "\n",
    "total_chunks = 0\n",
    "for i, chapter in enumerate(all_helix_data):\n",
    "    category_name = category_list[i]\n",
    "    chapter_chunks = sum(len(sub['chunks']) for sub in chapter['subchapters'])\n",
    "    total_chunks += chapter_chunks\n",
    "    print(f\"  Chapter {chapter['id']} ({category_name}): {len(chapter['subchapters'])} files, {chapter_chunks} chunks\")\n",
    "\n",
    "print(f\"\\n{len(all_helix_data)} chapters, {total_chunks} chunks across all categories\")\n",
    "\n",
    "try:\n",
    "    load_all_query = load_docs_rag(all_helix_data)\n",
    "    result = db.query(load_all_query)\n",
    "    print(f\"✅ HelixDB full load result: {result}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"error loading all data: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "951470c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[HELIX]\u001b[0m Querying 'http://0.0.0.0:6969/search_docs_rag': 100%|██████████| 1/1 [00:00<00:00, 28.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1: avitem.md\n",
      "Content: ---\n",
      "\n",
      "### AVItem.footageMissing\n",
      "\n",
      "`app.project.item(index).footageMissing`\n",
      "\n",
      "#### Description\n",
      "\n",
      "When `true`, the AVItem is a placeholder, or represents footage with a source file that cannot be found. In this case, the path of the missing source file is in the `missingFootagePath` attribute of the footage item's source-file object. See [FootageItem.mainSource](footageitem.md#footageitemmainsource) and [FileSource.missingFootagePath](../sources/filesource.md#filesourcemissingfootagepath).\n",
      "\n",
      "#### Type\n",
      "\n",
      "Boolean; read-only.\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Result 2: avitem.md\n",
      "Content: ---\n",
      "\n",
      "## Methods\n",
      "\n",
      "### AVItem.setProxy()\n",
      "\n",
      "`app.project.item(index).setProxy(file)`\n",
      "\n",
      "#### Description\n",
      "\n",
      "Sets a file as the proxy of this AVItem.\n",
      "\n",
      "Loads the specified file into a new FileSource object, sets this as the value of the `proxySource` attribute, and sets `useProxy` to `true`.\n",
      "\n",
      "It does not preserve the interpretation parameters, instead using the user preferences. If the file has an unlabeled alpha channel, and the user preference says to ask the user what to do, the method estimates the alpha interpretation, rather than asking the user.\n",
      "\n",
      "This differs from setting a FootageItem's `mainSource`, but both actions are performed as in the user interface.\n",
      "\n",
      "#### Parameters\n",
      "\n",
      "| Parameter |                                                 Type                                                  |           Description           |\n",
      "| --------- | ----------------------------------------------------------------------------------------------------- | ------------------------------- |\n",
      "| `file`    | [Extendscript File](https://extendscript.docsforadobe.dev/file-system-access/file-object.html) object | The file to be used as a proxy. |\n",
      "\n",
      "#### Returns\n",
      "\n",
      "None.\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Result 3: avlayer.md\n",
      "Content: ---\n",
      "\n",
      "### AVLayer.replaceSource()\n",
      "\n",
      "`app.project.item(index).layer(index).replaceSource(newSource, fixExpressions)`\n",
      "\n",
      "#### Description\n",
      "\n",
      "Replaces the source for this layer.\n",
      "\n",
      "!!! warning\n",
      "    If this method is performed on a null layer, the layers `isNull` attribute is not changed from `true`. This causes the layer not to be visible in comp viewer and renders.\n",
      "\n",
      "#### Parameters\n",
      "\n",
      "+------------------+------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|    Parameter     |                Type                |                                                                                                       Description                                                                                                        |\n",
      "+==================+====================================+==========================================================================================================================================================================================================================+\n",
      "| `newSource`      | [AVItem object](../item/avitem.md) | The new source AVItem object.                                                                                                                                                                                            |\n",
      "+------------------+------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| `fixExpressions` | Boolean                            | `true` to adjust expressions for the new source, otherwise `false`.                                                                                                                                                      |\n",
      "|                  |                                    |                                                                                                                                                                                                                          |\n",
      "|                  |                                    | !!! warning                                                                                                                                                                                                              |\n",
      "|                  |                                    |      This feature can be resource-intensive; if replacing a large amount of footage, do this only at the end of the operation. See also [Project.autoFixExpressions()](../general/project.md#projectautofixexpressions). |\n",
      "+------------------+------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "#### Returns\n",
      "\n",
      "Nothing.\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Result 4: avitem.md\n",
      "Content: ---\n",
      "\n",
      "### AVItem.name\n",
      "\n",
      "`app.project.item(index).name`\n",
      "\n",
      "#### Description\n",
      "\n",
      "The name of the item, as shown in the Project panel.\n",
      "\n",
      "- In a FootageItem, the value is linked to the `mainSource` object. If the `mainSource` object is a `FileSource`, this value controls the display name in the Project panel, but does not affect the file name.\n",
      "\n",
      "#### Type\n",
      "\n",
      "String; read/write.\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Result 5: project.md\n",
      "Content: # Project object\n",
      "\n",
      "`app.project`\n",
      "\n",
      "#### Description\n",
      "\n",
      "The project object represents an After Effects project. Attributes provide access to specific objects within the project, such as imported files or footage and compositions, and also to project settings such as the timecode base. Methods can import footage, create solids, compositions and folders, and save changes.\n",
      "────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#search the adobe after effects docs\n",
    "def search_ae_docs(user_question, top_k=5):\n",
    "\n",
    "    try:\n",
    "        #embed the user question\n",
    "        result = client.models.embed_content(\n",
    "            model=\"models/text-embedding-004\",\n",
    "            contents=user_question,\n",
    "            config=types.EmbedContentConfig(task_type=\"QUESTION_ANSWERING\")\n",
    "        )\n",
    "        #extract the embedding\n",
    "        query_embedding = result.embeddings[0].values\n",
    "        #search the docs\n",
    "\n",
    "        ## NOTE: there is a little bug in helixdb that is currently being fixed - the total chunks is hardcoded for now\n",
    "        total_chunks = 748\n",
    "        search_query = search_docs_rag(query_embedding, k=total_chunks)\n",
    "        search_results = db.query(search_query)\n",
    "        \n",
    "        if search_results and search_results[0]:\n",
    "            all_results = search_results[0].get('embedding_edges', [])\n",
    "            \n",
    "            # NOTE: bug that is being fixed - the results are reversed for now (list is flipped currently in Rust implementation)\n",
    "            reversed_results = list(reversed(all_results))\n",
    "            top_results = reversed_results[:top_k]\n",
    "        \n",
    "            \n",
    "            #print the results\n",
    "            for i, result in enumerate(top_results):\n",
    "                chunk = result.get('chunk', 'No chunk content')\n",
    "                if isinstance(chunk, list) and len(chunk) > 0:\n",
    "                    chunk = chunk[0]\n",
    "                #print the subchapter title\n",
    "                subchapter_title = result.get('subchapter_title', 'Unknown file')\n",
    "                if isinstance(subchapter_title, list) and len(subchapter_title) > 0:\n",
    "                    subchapter_title = subchapter_title[0]\n",
    "                \n",
    "                print(f\"Result {i+1}: {subchapter_title}\")\n",
    "                print(f\"Content: {chunk}\")\n",
    "                print(\"─\" * 80)\n",
    "        else:\n",
    "            print(\"No results found\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error searching: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# question to test the search\n",
    "search_ae_docs(\"I imported a bunch of footage into my After Effects project but some of the files got moved or deleted from their original location. Now I have these red question mark placeholders showing up in my project panel. Can you write a script that goes through all my footage items and tells me which ones have broken file links? I also want to see the original file paths of the missing footage so I know where they used to be located.\", top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6150763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'api_key' in locals():\n",
    "    del api_key"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
